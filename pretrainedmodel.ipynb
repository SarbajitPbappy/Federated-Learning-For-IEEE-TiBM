{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b224ed05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# CELL 1: Imports & GPU Check\n",
    "import os, json, pathlib, warnings\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, applications, optimizers, callbacks\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras import mixed_precision\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from glob import glob\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "print(\"GPUs:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0856a726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 2: Configuration\n",
    "BASE_DATA_PATH = pathlib.Path(\"/Volumes/Sarbajit/Model Optimization/Data/Augmented\")\n",
    "\n",
    "modalities = {\n",
    "    # 'Brain_Tumor': 'Brain Tumor',\n",
    "    # 'Breast_Cancer': 'Breast Cancer',\n",
    "    # 'Kidney_Cancer': 'Kidney Cancer',\n",
    "    'Lymphoma': 'Lymphoma',\n",
    "    'Leukemia': 'Leukemia',\n",
    "    'Lung_Colon_Cancer': 'Lung and Colon Cancer',\n",
    "    'Oral_Cancer': 'Oral Cancer',\n",
    "    'Skin_Leison': 'Skin Leison',\n",
    "    'Chest_Xray': 'chest_xray',\n",
    "}\n",
    "\n",
    "OUTPUT_ROOT = pathlib.Path(\"/Volumes/Sarbajit/Model Optimization/Transfer Learning Model/Output\")\n",
    "OUTPUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100\n",
    "LR = 1e-4\n",
    "INPUT_SHAPE = (224, 224, 3)\n",
    "PATIENCE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "394f3482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 3: Helper Functions (fixed for shape & label consistency)\n",
    "# ============================================================\n",
    "\n",
    "def get_class_names(gen):\n",
    "    return list(gen.class_indices.keys())\n",
    "\n",
    "def compute_class_weights(train_gen):\n",
    "    \"\"\"Compute class weights from training generator.\"\"\"\n",
    "    labels = train_gen.classes\n",
    "    class_weights = compute_class_weight(\n",
    "        class_weight='balanced',\n",
    "        classes=np.unique(labels),\n",
    "        y=labels\n",
    "    )\n",
    "    cw_dict = {i: w for i, w in enumerate(class_weights)}\n",
    "    # Ensure all classes have weights\n",
    "    for i in range(len(train_gen.class_indices)):\n",
    "        cw_dict.setdefault(i, 1.0)\n",
    "    return cw_dict\n",
    "\n",
    "def save_history_plot(hist, out_dir):\n",
    "    df = pd.DataFrame(hist.history)\n",
    "    for cols, name in [(['accuracy', 'val_accuracy'], 'accuracy'), (['loss', 'val_loss'], 'loss')]:\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        df[cols].plot(title=name.capitalize())\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(out_dir / f\"{name}_curve.png\", dpi=600)\n",
    "        plt.close()\n",
    "\n",
    "def save_confusion_matrix(y_true, y_pred, classes, out_dir):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=range(len(classes)))\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=classes, yticklabels=classes)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_dir / 'confusion_matrix.png', dpi=600)\n",
    "    plt.close()\n",
    "\n",
    "def save_classification_report(y_true, y_pred, classes, out_dir):\n",
    "    report = classification_report(y_true, y_pred,\n",
    "                                   target_names=classes, output_dict=True, zero_division=0)\n",
    "    json.dump(report, open(out_dir / 'classification_report.json', 'w'), indent=2)\n",
    "    with open(out_dir / 'classification_report.txt', 'w') as f:\n",
    "        f.write(classification_report(y_true, y_pred, target_names=classes, zero_division=0))\n",
    "    df = pd.DataFrame(report).T.iloc[:-3][['precision', 'recall', 'f1-score']]\n",
    "    df.plot(kind='bar', figsize=(10, 8), title='Per-Class Metrics')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_dir / 'classification_metrics.png', dpi=600)\n",
    "    plt.close()\n",
    "\n",
    "def save_roc_auc(y_true_onehot, y_pred_proba, classes, out_dir):\n",
    "    \"\"\"Robust ROC AUC plotting for binary and multiclass cases.\"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Handle binary classification\n",
    "    if len(classes) == 2:\n",
    "        # Ensure consistent 2D shape\n",
    "        if y_pred_proba.ndim == 1 or y_pred_proba.shape[1] == 1:\n",
    "            y_pred_proba = np.hstack([1 - y_pred_proba.reshape(-1, 1),\n",
    "                                      y_pred_proba.reshape(-1, 1)])\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_true_onehot[:, 1], y_pred_proba[:, 1])\n",
    "        auc = roc_auc_score(y_true_onehot[:, 1], y_pred_proba[:, 1])\n",
    "        plt.plot(fpr, tpr, label=f'ROC (AUC = {auc:.3f})')\n",
    "\n",
    "    # Multiclass case\n",
    "    else:\n",
    "        for i, cls in enumerate(classes):\n",
    "            fpr, tpr, _ = roc_curve(y_true_onehot[:, i], y_pred_proba[:, i])\n",
    "            auc = roc_auc_score(y_true_onehot[:, i], y_pred_proba[:, i])\n",
    "            plt.plot(fpr, tpr, label=f'{cls} (AUC = {auc:.3f})')\n",
    "        # Add macro-average ROC\n",
    "        macro_auc = roc_auc_score(y_true_onehot, y_pred_proba,\n",
    "                                  average='macro', multi_class='ovr')\n",
    "        plt.plot([], [], ' ', label=f'Macro-AUC = {macro_auc:.3f}')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], '--', color='gray')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_dir / 'roc_auc.png', dpi=600)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "338368a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 4: Model Builders (unchanged, just stylistic cleanup)\n",
    "# ============================================================\n",
    "\n",
    "def create_resnet50v2_model(num_classes):\n",
    "    base = applications.ResNet50V2(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)\n",
    "    base.trainable = False\n",
    "    x = layers.GlobalAveragePooling2D()(base.output)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    if num_classes == 2:\n",
    "        head = layers.Dense(1, activation='sigmoid', name='head')(x)\n",
    "        loss = 'binary_crossentropy'\n",
    "    else:\n",
    "        head = layers.Dense(num_classes, activation='softmax', name='head')(x)\n",
    "        loss = 'categorical_crossentropy'\n",
    "    model = models.Model(inputs=base.input, outputs=head, name=f'ResNet50V2_{num_classes}cls')\n",
    "    model.compile(optimizer=optimizers.Adam(LR), loss=loss, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_vgg19_model(num_classes):\n",
    "    base = applications.VGG19(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)\n",
    "    base.trainable = False\n",
    "    x = layers.GlobalAveragePooling2D()(base.output)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    if num_classes == 2:\n",
    "        head = layers.Dense(1, activation='sigmoid')(x)\n",
    "        loss = 'binary_crossentropy'\n",
    "    else:\n",
    "        head = layers.Dense(num_classes, activation='softmax')(x)\n",
    "        loss = 'categorical_crossentropy'\n",
    "    model = models.Model(base.input, head, name=f'VGG19_{num_classes}cls')\n",
    "    model.compile(optimizer=optimizers.Adam(LR), loss=loss, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def create_mobilenetv3_model(num_classes):\n",
    "    base = applications.MobileNetV3Large(weights='imagenet', include_top=False, input_shape=INPUT_SHAPE)\n",
    "    base.trainable = False\n",
    "    x = layers.GlobalAveragePooling2D()(base.output)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    if num_classes == 2:\n",
    "        head = layers.Dense(1, activation='sigmoid')(x)\n",
    "        loss = 'binary_crossentropy'\n",
    "    else:\n",
    "        head = layers.Dense(num_classes, activation='softmax')(x)\n",
    "        loss = 'categorical_crossentropy'\n",
    "    model = models.Model(base.input, head, name=f'MobileNetV3_{num_classes}cls')\n",
    "    model.compile(optimizer=optimizers.Adam(LR), loss=loss, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "MODEL_BUILDERS = {\n",
    "    'resnet50v2': create_resnet50v2_model,\n",
    "    'vgg19': create_vgg19_model,\n",
    "    'mobilenetv3': create_mobilenetv3_model,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "300d7155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 5: Data Loading & Generators (unchanged except safety)\n",
    "# ============================================================\n",
    "\n",
    "def load_dataframe(dataset_folder):\n",
    "    paths, labels = [], []\n",
    "    for cls in sorted(os.listdir(dataset_folder)):\n",
    "        cls_path = dataset_folder / cls\n",
    "        if not cls_path.is_dir():\n",
    "            continue\n",
    "        for ext in ('*.jpg', '*.jpeg', '*.png', '*.bmp'):\n",
    "            found = glob(str(cls_path / ext))\n",
    "            paths.extend(found)\n",
    "            labels.extend([cls] * len(found))\n",
    "    df = pd.DataFrame({'Filepath': paths, 'Label': labels})\n",
    "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def create_generators(df):\n",
    "    train_df, temp = train_test_split(df, test_size=0.30, stratify=df['Label'], random_state=42)\n",
    "    val_df, test_df = train_test_split(temp, test_size=0.50, stratify=temp['Label'], random_state=42)\n",
    "\n",
    "    n_classes = df['Label'].nunique()\n",
    "    class_mode = 'binary' if n_classes == 2 else 'categorical'\n",
    "\n",
    "    datagen = ImageDataGenerator(\n",
    "        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "    )\n",
    "\n",
    "    train_gen = datagen.flow_from_dataframe(\n",
    "        train_df, x_col='Filepath', y_col='Label',\n",
    "        target_size=INPUT_SHAPE[:2], batch_size=BATCH_SIZE,\n",
    "        class_mode=class_mode, shuffle=True\n",
    "    )\n",
    "    val_gen = datagen.flow_from_dataframe(\n",
    "        val_df, x_col='Filepath', y_col='Label',\n",
    "        target_size=INPUT_SHAPE[:2], batch_size=BATCH_SIZE,\n",
    "        class_mode=class_mode, shuffle=False\n",
    "    )\n",
    "    test_gen = datagen.flow_from_dataframe(\n",
    "        test_df, x_col='Filepath', y_col='Label',\n",
    "        target_size=INPUT_SHAPE[:2], batch_size=BATCH_SIZE,\n",
    "        class_mode=class_mode, shuffle=False\n",
    "    )\n",
    "    return train_gen, val_gen, test_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d528919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DATASET: Lymphoma (Lymphoma)\n",
      "================================================================================\n",
      "   → 4500 images | 3 classes\n",
      "Found 3150 validated image filenames belonging to 3 classes.\n",
      "Found 675 validated image filenames belonging to 3 classes.\n",
      "Found 675 validated image filenames belonging to 3 classes.\n",
      "   → Class weights: {0: 1.0, 1: 1.0, 2: 1.0}\n",
      "\n",
      "--- Training RESNET50V2 on Lymphoma ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 23:51:57.439912: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4\n",
      "2025-11-07 23:51:57.439944: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-11-07 23:51:57.439947: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.92 GB\n",
      "2025-11-07 23:51:57.439962: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-11-07 23:51:57.439971: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-07 23:51:59.146950: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 123ms/step - accuracy: 0.3794 - loss: 1.2294 - val_accuracy: 0.4593 - val_loss: 1.0275\n",
      "Epoch 2/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 107ms/step - accuracy: 0.4632 - loss: 1.0575 - val_accuracy: 0.5585 - val_loss: 0.9136\n",
      "Epoch 3/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 110ms/step - accuracy: 0.5124 - loss: 0.9662 - val_accuracy: 0.6341 - val_loss: 0.8487\n",
      "Epoch 4/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 108ms/step - accuracy: 0.5721 - loss: 0.9071 - val_accuracy: 0.6637 - val_loss: 0.7986\n",
      "Epoch 5/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 196ms/step - accuracy: 0.5981 - loss: 0.8603 - val_accuracy: 0.6993 - val_loss: 0.7624\n",
      "Epoch 6/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 263ms/step - accuracy: 0.6286 - loss: 0.8216 - val_accuracy: 0.7081 - val_loss: 0.7326\n",
      "Epoch 7/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 263ms/step - accuracy: 0.6375 - loss: 0.8013 - val_accuracy: 0.7304 - val_loss: 0.7075\n",
      "Epoch 8/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 259ms/step - accuracy: 0.6489 - loss: 0.7792 - val_accuracy: 0.7393 - val_loss: 0.6854\n",
      "Epoch 9/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 256ms/step - accuracy: 0.6898 - loss: 0.7488 - val_accuracy: 0.7407 - val_loss: 0.6677\n",
      "Epoch 10/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 253ms/step - accuracy: 0.6943 - loss: 0.7299 - val_accuracy: 0.7570 - val_loss: 0.6512\n",
      "Epoch 11/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 249ms/step - accuracy: 0.6952 - loss: 0.7140 - val_accuracy: 0.7674 - val_loss: 0.6360\n",
      "Epoch 12/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 250ms/step - accuracy: 0.7171 - loss: 0.6891 - val_accuracy: 0.7674 - val_loss: 0.6222\n",
      "Epoch 13/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 250ms/step - accuracy: 0.7140 - loss: 0.6877 - val_accuracy: 0.7837 - val_loss: 0.6112\n",
      "Epoch 14/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 239ms/step - accuracy: 0.7225 - loss: 0.6689 - val_accuracy: 0.7881 - val_loss: 0.6007\n",
      "Epoch 15/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 250ms/step - accuracy: 0.7308 - loss: 0.6551 - val_accuracy: 0.7822 - val_loss: 0.5905\n",
      "Epoch 16/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 244ms/step - accuracy: 0.7356 - loss: 0.6434 - val_accuracy: 0.7926 - val_loss: 0.5809\n",
      "Epoch 17/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 249ms/step - accuracy: 0.7359 - loss: 0.6405 - val_accuracy: 0.7926 - val_loss: 0.5729\n",
      "Epoch 18/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 251ms/step - accuracy: 0.7397 - loss: 0.6421 - val_accuracy: 0.8059 - val_loss: 0.5654\n",
      "Epoch 19/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 249ms/step - accuracy: 0.7476 - loss: 0.6244 - val_accuracy: 0.7985 - val_loss: 0.5593\n",
      "Epoch 20/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 250ms/step - accuracy: 0.7575 - loss: 0.6039 - val_accuracy: 0.8133 - val_loss: 0.5500\n",
      "Epoch 21/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 251ms/step - accuracy: 0.7606 - loss: 0.6098 - val_accuracy: 0.8030 - val_loss: 0.5435\n",
      "Epoch 22/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 249ms/step - accuracy: 0.7708 - loss: 0.5907 - val_accuracy: 0.8030 - val_loss: 0.5379\n",
      "Epoch 23/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 251ms/step - accuracy: 0.7603 - loss: 0.5946 - val_accuracy: 0.8104 - val_loss: 0.5314\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 241ms/step\n",
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n",
      "Done → /Volumes/Sarbajit/Model Optimization/Transfer Learning Model/Output/resnet50v2/Lymphoma\n",
      "\n",
      "--- Training VGG19 on Lymphoma ---\n",
      "Epoch 1/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 276ms/step - accuracy: 0.3330 - loss: 1.2485 - val_accuracy: 0.3185 - val_loss: 1.1119\n",
      "Epoch 2/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 270ms/step - accuracy: 0.3403 - loss: 1.1835 - val_accuracy: 0.3274 - val_loss: 1.1015\n",
      "Epoch 3/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 273ms/step - accuracy: 0.3492 - loss: 1.1621 - val_accuracy: 0.3807 - val_loss: 1.0915\n",
      "Epoch 4/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 275ms/step - accuracy: 0.3502 - loss: 1.1505 - val_accuracy: 0.4356 - val_loss: 1.0825\n",
      "Epoch 5/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 271ms/step - accuracy: 0.3419 - loss: 1.1371 - val_accuracy: 0.4622 - val_loss: 1.0749\n",
      "Epoch 6/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 269ms/step - accuracy: 0.3562 - loss: 1.1271 - val_accuracy: 0.5319 - val_loss: 1.0669\n",
      "Epoch 7/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 272ms/step - accuracy: 0.3781 - loss: 1.1004 - val_accuracy: 0.5481 - val_loss: 1.0594\n",
      "Epoch 8/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 272ms/step - accuracy: 0.3952 - loss: 1.0914 - val_accuracy: 0.5689 - val_loss: 1.0524\n",
      "Epoch 9/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 272ms/step - accuracy: 0.4073 - loss: 1.0761 - val_accuracy: 0.5659 - val_loss: 1.0453\n",
      "Epoch 10/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 272ms/step - accuracy: 0.4146 - loss: 1.0758 - val_accuracy: 0.5659 - val_loss: 1.0395\n",
      "Epoch 11/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 271ms/step - accuracy: 0.4298 - loss: 1.0611 - val_accuracy: 0.5600 - val_loss: 1.0324\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 211ms/step\n",
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n",
      "Done → /Volumes/Sarbajit/Model Optimization/Transfer Learning Model/Output/vgg19/Lymphoma\n",
      "\n",
      "--- Training MOBILENETV3 on Lymphoma ---\n",
      "Epoch 1/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 201ms/step - accuracy: 0.3502 - loss: 1.1853 - val_accuracy: 0.2815 - val_loss: 1.0978\n",
      "Epoch 2/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 178ms/step - accuracy: 0.3365 - loss: 1.1487 - val_accuracy: 0.4770 - val_loss: 1.0914\n",
      "Epoch 3/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 176ms/step - accuracy: 0.3352 - loss: 1.1418 - val_accuracy: 0.4770 - val_loss: 1.0860\n",
      "Epoch 4/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 178ms/step - accuracy: 0.3540 - loss: 1.1182 - val_accuracy: 0.4904 - val_loss: 1.0803\n",
      "Epoch 5/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 178ms/step - accuracy: 0.3648 - loss: 1.1123 - val_accuracy: 0.4859 - val_loss: 1.0759\n",
      "Epoch 6/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 177ms/step - accuracy: 0.3794 - loss: 1.1005 - val_accuracy: 0.5022 - val_loss: 1.0717\n",
      "Epoch 7/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 176ms/step - accuracy: 0.3749 - loss: 1.0977 - val_accuracy: 0.5052 - val_loss: 1.0656\n",
      "Epoch 8/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 178ms/step - accuracy: 0.4067 - loss: 1.0834 - val_accuracy: 0.5185 - val_loss: 1.0610\n",
      "Epoch 9/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 169ms/step - accuracy: 0.3914 - loss: 1.0844 - val_accuracy: 0.4904 - val_loss: 1.0570\n",
      "Epoch 10/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 177ms/step - accuracy: 0.4054 - loss: 1.0735 - val_accuracy: 0.5022 - val_loss: 1.0538\n",
      "Epoch 11/100\n",
      "\u001b[1m197/197\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 177ms/step - accuracy: 0.4190 - loss: 1.0723 - val_accuracy: 0.4963 - val_loss: 1.0497\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 193ms/step\n",
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n",
      "Done → /Volumes/Sarbajit/Model Optimization/Transfer Learning Model/Output/mobilenetv3/Lymphoma\n",
      "\n",
      "================================================================================\n",
      "DATASET: Leukemia (Leukemia)\n",
      "================================================================================\n",
      "   → 6000 images | 4 classes\n",
      "Found 4200 validated image filenames belonging to 4 classes.\n",
      "Found 900 validated image filenames belonging to 4 classes.\n",
      "Found 900 validated image filenames belonging to 4 classes.\n",
      "   → Class weights: {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0}\n",
      "\n",
      "--- Training RESNET50V2 on Leukemia ---\n",
      "Epoch 1/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 275ms/step - accuracy: 0.5402 - loss: 1.1131 - val_accuracy: 0.8100 - val_loss: 0.7701\n",
      "Epoch 2/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 253ms/step - accuracy: 0.7612 - loss: 0.7286 - val_accuracy: 0.8800 - val_loss: 0.5636\n",
      "Epoch 3/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 254ms/step - accuracy: 0.8293 - loss: 0.5620 - val_accuracy: 0.8956 - val_loss: 0.4541\n",
      "Epoch 4/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 254ms/step - accuracy: 0.8640 - loss: 0.4742 - val_accuracy: 0.9156 - val_loss: 0.3847\n",
      "Epoch 5/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 255ms/step - accuracy: 0.8826 - loss: 0.4176 - val_accuracy: 0.9289 - val_loss: 0.3365\n",
      "Epoch 6/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 255ms/step - accuracy: 0.8998 - loss: 0.3713 - val_accuracy: 0.9378 - val_loss: 0.3011\n",
      "Epoch 7/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 247ms/step - accuracy: 0.9095 - loss: 0.3346 - val_accuracy: 0.9356 - val_loss: 0.2761\n",
      "Epoch 8/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 254ms/step - accuracy: 0.9193 - loss: 0.3067 - val_accuracy: 0.9422 - val_loss: 0.2536\n",
      "Epoch 9/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 253ms/step - accuracy: 0.9298 - loss: 0.2790 - val_accuracy: 0.9478 - val_loss: 0.2355\n",
      "Epoch 10/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 253ms/step - accuracy: 0.9321 - loss: 0.2652 - val_accuracy: 0.9511 - val_loss: 0.2195\n",
      "Epoch 11/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 253ms/step - accuracy: 0.9360 - loss: 0.2494 - val_accuracy: 0.9522 - val_loss: 0.2074\n",
      "Epoch 12/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 254ms/step - accuracy: 0.9374 - loss: 0.2328 - val_accuracy: 0.9578 - val_loss: 0.1964\n",
      "Epoch 13/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 253ms/step - accuracy: 0.9383 - loss: 0.2238 - val_accuracy: 0.9556 - val_loss: 0.1877\n",
      "Epoch 14/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 255ms/step - accuracy: 0.9440 - loss: 0.2140 - val_accuracy: 0.9589 - val_loss: 0.1782\n",
      "Epoch 15/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 253ms/step - accuracy: 0.9481 - loss: 0.2025 - val_accuracy: 0.9578 - val_loss: 0.1715\n",
      "Epoch 16/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 258ms/step - accuracy: 0.9464 - loss: 0.1988 - val_accuracy: 0.9589 - val_loss: 0.1665\n",
      "Epoch 17/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 256ms/step - accuracy: 0.9538 - loss: 0.1870 - val_accuracy: 0.9611 - val_loss: 0.1596\n",
      "Epoch 18/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 255ms/step - accuracy: 0.9517 - loss: 0.1812 - val_accuracy: 0.9633 - val_loss: 0.1554\n",
      "Epoch 19/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 255ms/step - accuracy: 0.9552 - loss: 0.1755 - val_accuracy: 0.9667 - val_loss: 0.1496\n",
      "Epoch 20/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 254ms/step - accuracy: 0.9552 - loss: 0.1669 - val_accuracy: 0.9656 - val_loss: 0.1450\n",
      "Epoch 21/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 253ms/step - accuracy: 0.9593 - loss: 0.1600 - val_accuracy: 0.9656 - val_loss: 0.1411\n",
      "Epoch 22/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 254ms/step - accuracy: 0.9550 - loss: 0.1626 - val_accuracy: 0.9678 - val_loss: 0.1376\n",
      "Epoch 23/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 251ms/step - accuracy: 0.9564 - loss: 0.1587 - val_accuracy: 0.9656 - val_loss: 0.1366\n",
      "Epoch 24/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 253ms/step - accuracy: 0.9624 - loss: 0.1473 - val_accuracy: 0.9667 - val_loss: 0.1323\n",
      "Epoch 25/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 253ms/step - accuracy: 0.9605 - loss: 0.1498 - val_accuracy: 0.9678 - val_loss: 0.1286\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 294ms/step\n",
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n",
      "Done → /Volumes/Sarbajit/Model Optimization/Transfer Learning Model/Output/resnet50v2/Leukemia\n",
      "\n",
      "--- Training VGG19 on Leukemia ---\n",
      "Epoch 1/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 275ms/step - accuracy: 0.3486 - loss: 1.4170 - val_accuracy: 0.6078 - val_loss: 1.2371\n",
      "Epoch 2/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 272ms/step - accuracy: 0.4917 - loss: 1.2221 - val_accuracy: 0.7489 - val_loss: 1.1401\n",
      "Epoch 3/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 268ms/step - accuracy: 0.5802 - loss: 1.1328 - val_accuracy: 0.7856 - val_loss: 1.0569\n",
      "Epoch 4/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 268ms/step - accuracy: 0.6540 - loss: 1.0608 - val_accuracy: 0.8056 - val_loss: 0.9852\n",
      "Epoch 5/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 272ms/step - accuracy: 0.6976 - loss: 0.9895 - val_accuracy: 0.8278 - val_loss: 0.9211\n",
      "Epoch 6/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 269ms/step - accuracy: 0.7348 - loss: 0.9289 - val_accuracy: 0.8444 - val_loss: 0.8659\n",
      "Epoch 7/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 269ms/step - accuracy: 0.7748 - loss: 0.8709 - val_accuracy: 0.8478 - val_loss: 0.8159\n",
      "Epoch 8/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 267ms/step - accuracy: 0.7864 - loss: 0.8243 - val_accuracy: 0.8633 - val_loss: 0.7739\n",
      "Epoch 9/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 271ms/step - accuracy: 0.7971 - loss: 0.7889 - val_accuracy: 0.8656 - val_loss: 0.7342\n",
      "Epoch 10/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 269ms/step - accuracy: 0.8193 - loss: 0.7396 - val_accuracy: 0.8622 - val_loss: 0.6983\n",
      "Epoch 11/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 269ms/step - accuracy: 0.8214 - loss: 0.7178 - val_accuracy: 0.8678 - val_loss: 0.6662\n",
      "Epoch 12/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 270ms/step - accuracy: 0.8264 - loss: 0.6930 - val_accuracy: 0.8722 - val_loss: 0.6379\n",
      "Epoch 13/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 270ms/step - accuracy: 0.8390 - loss: 0.6610 - val_accuracy: 0.8756 - val_loss: 0.6120\n",
      "Epoch 14/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 270ms/step - accuracy: 0.8407 - loss: 0.6397 - val_accuracy: 0.8811 - val_loss: 0.5887\n",
      "Epoch 15/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 270ms/step - accuracy: 0.8462 - loss: 0.6187 - val_accuracy: 0.8878 - val_loss: 0.5668\n",
      "Epoch 16/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 268ms/step - accuracy: 0.8605 - loss: 0.5881 - val_accuracy: 0.8889 - val_loss: 0.5461\n",
      "Epoch 17/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 272ms/step - accuracy: 0.8590 - loss: 0.5760 - val_accuracy: 0.8900 - val_loss: 0.5274\n",
      "Epoch 18/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 271ms/step - accuracy: 0.8674 - loss: 0.5540 - val_accuracy: 0.8944 - val_loss: 0.5098\n",
      "Epoch 19/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 271ms/step - accuracy: 0.8664 - loss: 0.5404 - val_accuracy: 0.9044 - val_loss: 0.4939\n",
      "Epoch 20/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 270ms/step - accuracy: 0.8705 - loss: 0.5275 - val_accuracy: 0.9044 - val_loss: 0.4788\n",
      "Epoch 21/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 272ms/step - accuracy: 0.8767 - loss: 0.5107 - val_accuracy: 0.9056 - val_loss: 0.4644\n",
      "Epoch 22/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 273ms/step - accuracy: 0.8793 - loss: 0.4918 - val_accuracy: 0.9056 - val_loss: 0.4512\n",
      "Epoch 23/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 270ms/step - accuracy: 0.8843 - loss: 0.4820 - val_accuracy: 0.9067 - val_loss: 0.4389\n",
      "Epoch 24/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 271ms/step - accuracy: 0.8848 - loss: 0.4718 - val_accuracy: 0.9078 - val_loss: 0.4270\n",
      "Epoch 25/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 272ms/step - accuracy: 0.8950 - loss: 0.4591 - val_accuracy: 0.9100 - val_loss: 0.4159\n",
      "Epoch 26/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 272ms/step - accuracy: 0.8957 - loss: 0.4494 - val_accuracy: 0.9133 - val_loss: 0.4051\n",
      "Epoch 27/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 270ms/step - accuracy: 0.8900 - loss: 0.4426 - val_accuracy: 0.9167 - val_loss: 0.3955\n",
      "Epoch 28/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 271ms/step - accuracy: 0.8979 - loss: 0.4329 - val_accuracy: 0.9189 - val_loss: 0.3862\n",
      "Epoch 29/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 271ms/step - accuracy: 0.8943 - loss: 0.4246 - val_accuracy: 0.9189 - val_loss: 0.3774\n",
      "Epoch 30/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 271ms/step - accuracy: 0.9010 - loss: 0.4128 - val_accuracy: 0.9211 - val_loss: 0.3690\n",
      "Epoch 31/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 272ms/step - accuracy: 0.8983 - loss: 0.4117 - val_accuracy: 0.9244 - val_loss: 0.3611\n",
      "Epoch 32/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 271ms/step - accuracy: 0.8979 - loss: 0.3986 - val_accuracy: 0.9244 - val_loss: 0.3536\n",
      "Epoch 33/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 273ms/step - accuracy: 0.9079 - loss: 0.3919 - val_accuracy: 0.9300 - val_loss: 0.3465\n",
      "Epoch 34/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 272ms/step - accuracy: 0.9143 - loss: 0.3767 - val_accuracy: 0.9289 - val_loss: 0.3394\n",
      "Epoch 35/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 273ms/step - accuracy: 0.9069 - loss: 0.3750 - val_accuracy: 0.9322 - val_loss: 0.3333\n",
      "Epoch 36/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 272ms/step - accuracy: 0.9076 - loss: 0.3735 - val_accuracy: 0.9300 - val_loss: 0.3265\n",
      "Epoch 37/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 273ms/step - accuracy: 0.9074 - loss: 0.3698 - val_accuracy: 0.9333 - val_loss: 0.3208\n",
      "Epoch 38/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 271ms/step - accuracy: 0.9150 - loss: 0.3565 - val_accuracy: 0.9311 - val_loss: 0.3152\n",
      "Epoch 39/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 272ms/step - accuracy: 0.9174 - loss: 0.3490 - val_accuracy: 0.9367 - val_loss: 0.3096\n",
      "Epoch 40/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 271ms/step - accuracy: 0.9169 - loss: 0.3439 - val_accuracy: 0.9367 - val_loss: 0.3046\n",
      "Epoch 41/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 273ms/step - accuracy: 0.9155 - loss: 0.3433 - val_accuracy: 0.9378 - val_loss: 0.2993\n",
      "Epoch 42/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 272ms/step - accuracy: 0.9186 - loss: 0.3360 - val_accuracy: 0.9367 - val_loss: 0.2947\n",
      "Epoch 43/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 271ms/step - accuracy: 0.9124 - loss: 0.3381 - val_accuracy: 0.9433 - val_loss: 0.2900\n",
      "Epoch 44/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 273ms/step - accuracy: 0.9217 - loss: 0.3248 - val_accuracy: 0.9400 - val_loss: 0.2853\n",
      "Epoch 45/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 272ms/step - accuracy: 0.9186 - loss: 0.3275 - val_accuracy: 0.9411 - val_loss: 0.2814\n",
      "Epoch 46/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 273ms/step - accuracy: 0.9205 - loss: 0.3255 - val_accuracy: 0.9411 - val_loss: 0.2773\n",
      "Epoch 46: early stopping\n",
      "Restoring model weights from the end of the best epoch: 43.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 208ms/step\n",
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n",
      "Done → /Volumes/Sarbajit/Model Optimization/Transfer Learning Model/Output/vgg19/Leukemia\n",
      "\n",
      "--- Training MOBILENETV3 on Leukemia ---\n",
      "Epoch 1/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 198ms/step - accuracy: 0.2671 - loss: 1.4323 - val_accuracy: 0.3200 - val_loss: 1.3437\n",
      "Epoch 2/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 173ms/step - accuracy: 0.3210 - loss: 1.3679 - val_accuracy: 0.4533 - val_loss: 1.2999\n",
      "Epoch 3/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 187ms/step - accuracy: 0.3560 - loss: 1.3325 - val_accuracy: 0.5756 - val_loss: 1.2644\n",
      "Epoch 4/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 143ms/step - accuracy: 0.3852 - loss: 1.2924 - val_accuracy: 0.5800 - val_loss: 1.2340\n",
      "Epoch 5/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 171ms/step - accuracy: 0.4324 - loss: 1.2556 - val_accuracy: 0.5867 - val_loss: 1.2086\n",
      "Epoch 6/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 174ms/step - accuracy: 0.4560 - loss: 1.2286 - val_accuracy: 0.5956 - val_loss: 1.1858\n",
      "Epoch 7/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 175ms/step - accuracy: 0.4650 - loss: 1.2139 - val_accuracy: 0.5589 - val_loss: 1.1672\n",
      "Epoch 8/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 175ms/step - accuracy: 0.4926 - loss: 1.1895 - val_accuracy: 0.5878 - val_loss: 1.1493\n",
      "Epoch 9/100\n",
      "\u001b[1m263/263\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 176ms/step - accuracy: 0.5033 - loss: 1.1750 - val_accuracy: 0.5856 - val_loss: 1.1337\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 183ms/step\n",
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n",
      "Done → /Volumes/Sarbajit/Model Optimization/Transfer Learning Model/Output/mobilenetv3/Leukemia\n",
      "\n",
      "================================================================================\n",
      "DATASET: Lung and Colon Cancer (Lung_Colon_Cancer)\n",
      "================================================================================\n",
      "   → 20000 images | 4 classes\n",
      "Found 14000 validated image filenames belonging to 4 classes.\n",
      "Found 3000 validated image filenames belonging to 4 classes.\n",
      "Found 3000 validated image filenames belonging to 4 classes.\n",
      "   → Class weights: {0: 1.0, 1: 1.0, 2: 1.0, 3: 1.0}\n",
      "\n",
      "--- Training RESNET50V2 on Lung_Colon_Cancer ---\n",
      "Epoch 1/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m227s\u001b[0m 254ms/step - accuracy: 0.8140 - loss: 0.5127 - val_accuracy: 0.9713 - val_loss: 0.1528\n",
      "Epoch 2/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 252ms/step - accuracy: 0.9641 - loss: 0.1411 - val_accuracy: 0.9847 - val_loss: 0.0882\n",
      "Epoch 3/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 253ms/step - accuracy: 0.9753 - loss: 0.0937 - val_accuracy: 0.9870 - val_loss: 0.0656\n",
      "Epoch 4/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 253ms/step - accuracy: 0.9802 - loss: 0.0710 - val_accuracy: 0.9897 - val_loss: 0.0521\n",
      "Epoch 5/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 254ms/step - accuracy: 0.9854 - loss: 0.0565 - val_accuracy: 0.9917 - val_loss: 0.0436\n",
      "Epoch 6/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 254ms/step - accuracy: 0.9866 - loss: 0.0485 - val_accuracy: 0.9910 - val_loss: 0.0388\n",
      "Epoch 7/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 252ms/step - accuracy: 0.9900 - loss: 0.0406 - val_accuracy: 0.9937 - val_loss: 0.0344\n",
      "Epoch 8/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 254ms/step - accuracy: 0.9910 - loss: 0.0376 - val_accuracy: 0.9933 - val_loss: 0.0309\n",
      "Epoch 9/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 253ms/step - accuracy: 0.9919 - loss: 0.0327 - val_accuracy: 0.9930 - val_loss: 0.0281\n",
      "Epoch 10/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 255ms/step - accuracy: 0.9936 - loss: 0.0288 - val_accuracy: 0.9937 - val_loss: 0.0255\n",
      "Epoch 10: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 212ms/step\n",
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n",
      "Done → /Volumes/Sarbajit/Model Optimization/Transfer Learning Model/Output/resnet50v2/Lung_Colon_Cancer\n",
      "\n",
      "--- Training VGG19 on Lung_Colon_Cancer ---\n",
      "Epoch 1/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 271ms/step - accuracy: 0.5179 - loss: 1.2152 - val_accuracy: 0.8760 - val_loss: 0.8350\n",
      "Epoch 2/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 267ms/step - accuracy: 0.7907 - loss: 0.7401 - val_accuracy: 0.9197 - val_loss: 0.5662\n",
      "Epoch 3/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 266ms/step - accuracy: 0.8776 - loss: 0.5296 - val_accuracy: 0.9257 - val_loss: 0.4328\n",
      "Epoch 4/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m233s\u001b[0m 267ms/step - accuracy: 0.9086 - loss: 0.4215 - val_accuracy: 0.9297 - val_loss: 0.3544\n",
      "Epoch 5/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 267ms/step - accuracy: 0.9161 - loss: 0.3536 - val_accuracy: 0.9380 - val_loss: 0.3033\n",
      "Epoch 6/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 270ms/step - accuracy: 0.9252 - loss: 0.3127 - val_accuracy: 0.9383 - val_loss: 0.2686\n",
      "Epoch 7/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 269ms/step - accuracy: 0.9279 - loss: 0.2812 - val_accuracy: 0.9450 - val_loss: 0.2420\n",
      "Epoch 8/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 269ms/step - accuracy: 0.9329 - loss: 0.2571 - val_accuracy: 0.9463 - val_loss: 0.2223\n",
      "Epoch 9/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 269ms/step - accuracy: 0.9367 - loss: 0.2392 - val_accuracy: 0.9467 - val_loss: 0.2061\n",
      "Epoch 10/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 270ms/step - accuracy: 0.9353 - loss: 0.2248 - val_accuracy: 0.9500 - val_loss: 0.1940\n",
      "Epoch 11/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 271ms/step - accuracy: 0.9407 - loss: 0.2126 - val_accuracy: 0.9520 - val_loss: 0.1838\n",
      "Epoch 12/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 270ms/step - accuracy: 0.9428 - loss: 0.2028 - val_accuracy: 0.9540 - val_loss: 0.1746\n",
      "Epoch 13/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 270ms/step - accuracy: 0.9431 - loss: 0.1958 - val_accuracy: 0.9543 - val_loss: 0.1675\n",
      "Epoch 14/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 270ms/step - accuracy: 0.9438 - loss: 0.1892 - val_accuracy: 0.9577 - val_loss: 0.1603\n",
      "Epoch 15/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 270ms/step - accuracy: 0.9467 - loss: 0.1816 - val_accuracy: 0.9577 - val_loss: 0.1549\n",
      "Epoch 16/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 271ms/step - accuracy: 0.9474 - loss: 0.1735 - val_accuracy: 0.9593 - val_loss: 0.1498\n",
      "Epoch 17/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 269ms/step - accuracy: 0.9511 - loss: 0.1687 - val_accuracy: 0.9610 - val_loss: 0.1450\n",
      "Epoch 18/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 270ms/step - accuracy: 0.9499 - loss: 0.1655 - val_accuracy: 0.9613 - val_loss: 0.1417\n",
      "Epoch 19/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 488ms/step - accuracy: 0.9502 - loss: 0.1626 - val_accuracy: 0.9623 - val_loss: 0.1371\n",
      "Epoch 20/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m485s\u001b[0m 555ms/step - accuracy: 0.9504 - loss: 0.1570 - val_accuracy: 0.9643 - val_loss: 0.1339\n",
      "Epoch 21/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m496s\u001b[0m 567ms/step - accuracy: 0.9545 - loss: 0.1517 - val_accuracy: 0.9643 - val_loss: 0.1308\n",
      "Epoch 22/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m493s\u001b[0m 563ms/step - accuracy: 0.9525 - loss: 0.1521 - val_accuracy: 0.9640 - val_loss: 0.1275\n",
      "Epoch 23/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m503s\u001b[0m 575ms/step - accuracy: 0.9537 - loss: 0.1477 - val_accuracy: 0.9657 - val_loss: 0.1249\n",
      "Epoch 24/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m492s\u001b[0m 562ms/step - accuracy: 0.9564 - loss: 0.1414 - val_accuracy: 0.9643 - val_loss: 0.1229\n",
      "Epoch 25/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m496s\u001b[0m 567ms/step - accuracy: 0.9551 - loss: 0.1430 - val_accuracy: 0.9667 - val_loss: 0.1200\n",
      "Epoch 26/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m495s\u001b[0m 565ms/step - accuracy: 0.9570 - loss: 0.1401 - val_accuracy: 0.9667 - val_loss: 0.1183\n",
      "Epoch 27/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m503s\u001b[0m 575ms/step - accuracy: 0.9578 - loss: 0.1369 - val_accuracy: 0.9677 - val_loss: 0.1159\n",
      "Epoch 28/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m491s\u001b[0m 561ms/step - accuracy: 0.9597 - loss: 0.1347 - val_accuracy: 0.9690 - val_loss: 0.1140\n",
      "Epoch 29/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m493s\u001b[0m 564ms/step - accuracy: 0.9571 - loss: 0.1344 - val_accuracy: 0.9700 - val_loss: 0.1125\n",
      "Epoch 30/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m492s\u001b[0m 562ms/step - accuracy: 0.9578 - loss: 0.1326 - val_accuracy: 0.9690 - val_loss: 0.1105\n",
      "Epoch 31/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m500s\u001b[0m 572ms/step - accuracy: 0.9583 - loss: 0.1292 - val_accuracy: 0.9687 - val_loss: 0.1091\n",
      "Epoch 32/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m491s\u001b[0m 561ms/step - accuracy: 0.9591 - loss: 0.1290 - val_accuracy: 0.9707 - val_loss: 0.1072\n",
      "Epoch 33/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m499s\u001b[0m 570ms/step - accuracy: 0.9609 - loss: 0.1285 - val_accuracy: 0.9693 - val_loss: 0.1056\n",
      "Epoch 34/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m495s\u001b[0m 566ms/step - accuracy: 0.9614 - loss: 0.1274 - val_accuracy: 0.9697 - val_loss: 0.1044\n",
      "Epoch 35/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m495s\u001b[0m 566ms/step - accuracy: 0.9597 - loss: 0.1248 - val_accuracy: 0.9717 - val_loss: 0.1035\n",
      "Epoch 36/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m494s\u001b[0m 564ms/step - accuracy: 0.9605 - loss: 0.1228 - val_accuracy: 0.9707 - val_loss: 0.1014\n",
      "Epoch 37/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m495s\u001b[0m 566ms/step - accuracy: 0.9631 - loss: 0.1216 - val_accuracy: 0.9710 - val_loss: 0.1004\n",
      "Epoch 38/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m499s\u001b[0m 570ms/step - accuracy: 0.9626 - loss: 0.1223 - val_accuracy: 0.9720 - val_loss: 0.0989\n",
      "Epoch 39/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 488ms/step - accuracy: 0.9619 - loss: 0.1191 - val_accuracy: 0.9727 - val_loss: 0.0976\n",
      "Epoch 40/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m509s\u001b[0m 582ms/step - accuracy: 0.9616 - loss: 0.1191 - val_accuracy: 0.9723 - val_loss: 0.0967\n",
      "Epoch 41/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m506s\u001b[0m 578ms/step - accuracy: 0.9621 - loss: 0.1188 - val_accuracy: 0.9723 - val_loss: 0.0958\n",
      "Epoch 42/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m507s\u001b[0m 580ms/step - accuracy: 0.9615 - loss: 0.1173 - val_accuracy: 0.9727 - val_loss: 0.0949\n",
      "Epoch 42: early stopping\n",
      "Restoring model weights from the end of the best epoch: 39.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 411ms/step\n",
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n",
      "Done → /Volumes/Sarbajit/Model Optimization/Transfer Learning Model/Output/vgg19/Lung_Colon_Cancer\n",
      "\n",
      "--- Training MOBILENETV3 on Lung_Colon_Cancer ---\n",
      "Epoch 1/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m461s\u001b[0m 523ms/step - accuracy: 0.3921 - loss: 1.2961 - val_accuracy: 0.6357 - val_loss: 1.1505\n",
      "Epoch 2/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m452s\u001b[0m 516ms/step - accuracy: 0.5527 - loss: 1.1023 - val_accuracy: 0.6753 - val_loss: 1.0188\n",
      "Epoch 3/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m465s\u001b[0m 532ms/step - accuracy: 0.6122 - loss: 1.0000 - val_accuracy: 0.7057 - val_loss: 0.9336\n",
      "Epoch 4/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 517ms/step - accuracy: 0.6473 - loss: 0.9303 - val_accuracy: 0.7263 - val_loss: 0.8730\n",
      "Epoch 5/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m463s\u001b[0m 529ms/step - accuracy: 0.6706 - loss: 0.8781 - val_accuracy: 0.7430 - val_loss: 0.8261\n",
      "Epoch 6/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 517ms/step - accuracy: 0.6828 - loss: 0.8441 - val_accuracy: 0.7597 - val_loss: 0.7904\n",
      "Epoch 7/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m456s\u001b[0m 521ms/step - accuracy: 0.6949 - loss: 0.8087 - val_accuracy: 0.7673 - val_loss: 0.7586\n",
      "Epoch 8/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 530ms/step - accuracy: 0.7086 - loss: 0.7829 - val_accuracy: 0.7723 - val_loss: 0.7323\n",
      "Epoch 9/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m461s\u001b[0m 527ms/step - accuracy: 0.7130 - loss: 0.7619 - val_accuracy: 0.7790 - val_loss: 0.7103\n",
      "Epoch 10/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m453s\u001b[0m 518ms/step - accuracy: 0.7228 - loss: 0.7425 - val_accuracy: 0.7837 - val_loss: 0.6920\n",
      "Epoch 11/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m464s\u001b[0m 531ms/step - accuracy: 0.7276 - loss: 0.7261 - val_accuracy: 0.7827 - val_loss: 0.6737\n",
      "Epoch 12/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m451s\u001b[0m 516ms/step - accuracy: 0.7317 - loss: 0.7099 - val_accuracy: 0.7913 - val_loss: 0.6589\n",
      "Epoch 13/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m461s\u001b[0m 527ms/step - accuracy: 0.7359 - loss: 0.6984 - val_accuracy: 0.7873 - val_loss: 0.6461\n",
      "Epoch 14/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 281ms/step - accuracy: 0.7374 - loss: 0.6912 - val_accuracy: 0.7973 - val_loss: 0.6344\n",
      "Epoch 15/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 62ms/step - accuracy: 0.7449 - loss: 0.6772 - val_accuracy: 0.8033 - val_loss: 0.6235\n",
      "Epoch 16/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 65ms/step - accuracy: 0.7426 - loss: 0.6714 - val_accuracy: 0.8060 - val_loss: 0.6157\n",
      "Epoch 17/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 169ms/step - accuracy: 0.7475 - loss: 0.6598 - val_accuracy: 0.8077 - val_loss: 0.6057\n",
      "Epoch 18/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 179ms/step - accuracy: 0.7517 - loss: 0.6535 - val_accuracy: 0.8100 - val_loss: 0.5971\n",
      "Epoch 19/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 164ms/step - accuracy: 0.7554 - loss: 0.6458 - val_accuracy: 0.8117 - val_loss: 0.5896\n",
      "Epoch 20/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 182ms/step - accuracy: 0.7567 - loss: 0.6398 - val_accuracy: 0.8163 - val_loss: 0.5827\n",
      "Epoch 21/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 179ms/step - accuracy: 0.7554 - loss: 0.6362 - val_accuracy: 0.8127 - val_loss: 0.5757\n",
      "Epoch 22/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 172ms/step - accuracy: 0.7537 - loss: 0.6350 - val_accuracy: 0.8160 - val_loss: 0.5710\n",
      "Epoch 23/100\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 180ms/step - accuracy: 0.7631 - loss: 0.6219 - val_accuracy: 0.8143 - val_loss: 0.5644\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 172ms/step\n",
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n",
      "Done → /Volumes/Sarbajit/Model Optimization/Transfer Learning Model/Output/mobilenetv3/Lung_Colon_Cancer\n",
      "\n",
      "================================================================================\n",
      "DATASET: Oral Cancer (Oral_Cancer)\n",
      "================================================================================\n",
      "   → 5396 images | 2 classes\n",
      "Found 3777 validated image filenames belonging to 2 classes.\n",
      "Found 809 validated image filenames belonging to 2 classes.\n",
      "Found 810 validated image filenames belonging to 2 classes.\n",
      "   → Class weights: {0: 1.0002648305084745, 1: 0.9997353096876654}\n",
      "\n",
      "--- Training RESNET50V2 on Oral_Cancer ---\n",
      "Epoch 1/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 300ms/step - accuracy: 0.5806 - loss: 0.7149 - val_accuracy: 0.6564 - val_loss: 0.6140\n",
      "Epoch 2/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 255ms/step - accuracy: 0.6375 - loss: 0.6357 - val_accuracy: 0.7231 - val_loss: 0.5615\n",
      "Epoch 3/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 259ms/step - accuracy: 0.6974 - loss: 0.5777 - val_accuracy: 0.7664 - val_loss: 0.5261\n",
      "Epoch 4/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 267ms/step - accuracy: 0.7183 - loss: 0.5506 - val_accuracy: 0.7812 - val_loss: 0.5005\n",
      "Epoch 5/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 261ms/step - accuracy: 0.7389 - loss: 0.5198 - val_accuracy: 0.8010 - val_loss: 0.4810\n",
      "Epoch 6/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 264ms/step - accuracy: 0.7657 - loss: 0.4905 - val_accuracy: 0.8084 - val_loss: 0.4655\n",
      "Epoch 7/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 262ms/step - accuracy: 0.7805 - loss: 0.4757 - val_accuracy: 0.8171 - val_loss: 0.4540\n",
      "Epoch 8/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 261ms/step - accuracy: 0.7900 - loss: 0.4635 - val_accuracy: 0.8195 - val_loss: 0.4466\n",
      "Epoch 9/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 249ms/step - accuracy: 0.7988 - loss: 0.4508 - val_accuracy: 0.8257 - val_loss: 0.4356\n",
      "Epoch 10/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 246ms/step - accuracy: 0.8033 - loss: 0.4416 - val_accuracy: 0.8232 - val_loss: 0.4279\n",
      "Epoch 11/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 256ms/step - accuracy: 0.8014 - loss: 0.4362 - val_accuracy: 0.8232 - val_loss: 0.4212\n",
      "Epoch 12/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 263ms/step - accuracy: 0.8131 - loss: 0.4242 - val_accuracy: 0.8319 - val_loss: 0.4147\n",
      "Epoch 13/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 260ms/step - accuracy: 0.8155 - loss: 0.4236 - val_accuracy: 0.8368 - val_loss: 0.4114\n",
      "Epoch 14/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 259ms/step - accuracy: 0.8139 - loss: 0.4111 - val_accuracy: 0.8356 - val_loss: 0.4055\n",
      "Epoch 15/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 258ms/step - accuracy: 0.8181 - loss: 0.4117 - val_accuracy: 0.8418 - val_loss: 0.4009\n",
      "Epoch 16/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 260ms/step - accuracy: 0.8268 - loss: 0.4015 - val_accuracy: 0.8368 - val_loss: 0.3966\n",
      "Epoch 17/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 251ms/step - accuracy: 0.8181 - loss: 0.4045 - val_accuracy: 0.8381 - val_loss: 0.3933\n",
      "Epoch 18/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 252ms/step - accuracy: 0.8329 - loss: 0.3957 - val_accuracy: 0.8504 - val_loss: 0.3917\n",
      "Epoch 19/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 257ms/step - accuracy: 0.8292 - loss: 0.3893 - val_accuracy: 0.8381 - val_loss: 0.3867\n",
      "Epoch 20/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 259ms/step - accuracy: 0.8366 - loss: 0.3834 - val_accuracy: 0.8492 - val_loss: 0.3837\n",
      "Epoch 21/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 260ms/step - accuracy: 0.8358 - loss: 0.3796 - val_accuracy: 0.8504 - val_loss: 0.3800\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 280ms/step\n",
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n",
      "Done → /Volumes/Sarbajit/Model Optimization/Transfer Learning Model/Output/resnet50v2/Oral_Cancer\n",
      "\n",
      "--- Training VGG19 on Oral_Cancer ---\n",
      "Epoch 1/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 287ms/step - accuracy: 0.4917 - loss: 0.7806 - val_accuracy: 0.5538 - val_loss: 0.6961\n",
      "Epoch 2/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 276ms/step - accuracy: 0.5115 - loss: 0.7129 - val_accuracy: 0.5600 - val_loss: 0.6841\n",
      "Epoch 3/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 277ms/step - accuracy: 0.5113 - loss: 0.7097 - val_accuracy: 0.5859 - val_loss: 0.6759\n",
      "Epoch 4/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 271ms/step - accuracy: 0.5443 - loss: 0.6919 - val_accuracy: 0.6106 - val_loss: 0.6674\n",
      "Epoch 5/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 275ms/step - accuracy: 0.5462 - loss: 0.6838 - val_accuracy: 0.6242 - val_loss: 0.6596\n",
      "Epoch 6/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 275ms/step - accuracy: 0.5698 - loss: 0.6780 - val_accuracy: 0.6477 - val_loss: 0.6523\n",
      "Epoch 7/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 276ms/step - accuracy: 0.5931 - loss: 0.6664 - val_accuracy: 0.6724 - val_loss: 0.6460\n",
      "Epoch 8/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 275ms/step - accuracy: 0.6217 - loss: 0.6560 - val_accuracy: 0.6712 - val_loss: 0.6393\n",
      "Epoch 9/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 275ms/step - accuracy: 0.6206 - loss: 0.6512 - val_accuracy: 0.6897 - val_loss: 0.6331\n",
      "Epoch 10/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 275ms/step - accuracy: 0.6497 - loss: 0.6400 - val_accuracy: 0.6984 - val_loss: 0.6272\n",
      "Epoch 11/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 276ms/step - accuracy: 0.6574 - loss: 0.6365 - val_accuracy: 0.7033 - val_loss: 0.6221\n",
      "Epoch 12/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 273ms/step - accuracy: 0.6577 - loss: 0.6320 - val_accuracy: 0.7009 - val_loss: 0.6173\n",
      "Epoch 13/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 276ms/step - accuracy: 0.6751 - loss: 0.6271 - val_accuracy: 0.7083 - val_loss: 0.6125\n",
      "Epoch 14/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 277ms/step - accuracy: 0.6796 - loss: 0.6181 - val_accuracy: 0.7108 - val_loss: 0.6078\n",
      "Epoch 15/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 274ms/step - accuracy: 0.6751 - loss: 0.6157 - val_accuracy: 0.7095 - val_loss: 0.6034\n",
      "Epoch 16/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 273ms/step - accuracy: 0.6921 - loss: 0.6119 - val_accuracy: 0.7182 - val_loss: 0.5994\n",
      "Epoch 17/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 271ms/step - accuracy: 0.6947 - loss: 0.6066 - val_accuracy: 0.7219 - val_loss: 0.5957\n",
      "Epoch 18/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 275ms/step - accuracy: 0.7019 - loss: 0.6033 - val_accuracy: 0.7231 - val_loss: 0.5921\n",
      "Epoch 19/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 273ms/step - accuracy: 0.7074 - loss: 0.5990 - val_accuracy: 0.7244 - val_loss: 0.5887\n",
      "Epoch 20/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 279ms/step - accuracy: 0.7035 - loss: 0.5988 - val_accuracy: 0.7293 - val_loss: 0.5857\n",
      "Epoch 21/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 275ms/step - accuracy: 0.7066 - loss: 0.5930 - val_accuracy: 0.7293 - val_loss: 0.5828\n",
      "Epoch 22/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 274ms/step - accuracy: 0.7236 - loss: 0.5876 - val_accuracy: 0.7305 - val_loss: 0.5800\n",
      "Epoch 23/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 274ms/step - accuracy: 0.7122 - loss: 0.5897 - val_accuracy: 0.7342 - val_loss: 0.5768\n",
      "Epoch 24/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 274ms/step - accuracy: 0.7199 - loss: 0.5833 - val_accuracy: 0.7330 - val_loss: 0.5741\n",
      "Epoch 25/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 277ms/step - accuracy: 0.7194 - loss: 0.5817 - val_accuracy: 0.7355 - val_loss: 0.5718\n",
      "Epoch 26/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 274ms/step - accuracy: 0.7252 - loss: 0.5782 - val_accuracy: 0.7330 - val_loss: 0.5691\n",
      "Epoch 27/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 275ms/step - accuracy: 0.7188 - loss: 0.5758 - val_accuracy: 0.7355 - val_loss: 0.5667\n",
      "Epoch 28/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 272ms/step - accuracy: 0.7289 - loss: 0.5736 - val_accuracy: 0.7392 - val_loss: 0.5649\n",
      "Epoch 29/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 272ms/step - accuracy: 0.7204 - loss: 0.5762 - val_accuracy: 0.7367 - val_loss: 0.5624\n",
      "Epoch 30/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 276ms/step - accuracy: 0.7204 - loss: 0.5743 - val_accuracy: 0.7441 - val_loss: 0.5610\n",
      "Epoch 31/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 277ms/step - accuracy: 0.7294 - loss: 0.5671 - val_accuracy: 0.7429 - val_loss: 0.5587\n",
      "Epoch 32/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 273ms/step - accuracy: 0.7339 - loss: 0.5673 - val_accuracy: 0.7392 - val_loss: 0.5565\n",
      "Epoch 33/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 274ms/step - accuracy: 0.7318 - loss: 0.5616 - val_accuracy: 0.7417 - val_loss: 0.5549\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 30.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 248ms/step\n",
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n",
      "Done → /Volumes/Sarbajit/Model Optimization/Transfer Learning Model/Output/vgg19/Oral_Cancer\n",
      "\n",
      "--- Training MOBILENETV3 on Oral_Cancer ---\n",
      "Epoch 1/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 242ms/step - accuracy: 0.4983 - loss: 0.7550 - val_accuracy: 0.5019 - val_loss: 0.6999\n",
      "Epoch 2/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 186ms/step - accuracy: 0.5023 - loss: 0.7157 - val_accuracy: 0.4969 - val_loss: 0.6926\n",
      "Epoch 3/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 184ms/step - accuracy: 0.5081 - loss: 0.7086 - val_accuracy: 0.5303 - val_loss: 0.6895\n",
      "Epoch 4/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 185ms/step - accuracy: 0.5147 - loss: 0.7017 - val_accuracy: 0.5612 - val_loss: 0.6865\n",
      "Epoch 5/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 171ms/step - accuracy: 0.5160 - loss: 0.6994 - val_accuracy: 0.5735 - val_loss: 0.6838\n",
      "Epoch 6/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 178ms/step - accuracy: 0.5229 - loss: 0.6981 - val_accuracy: 0.5773 - val_loss: 0.6817\n",
      "Epoch 7/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 169ms/step - accuracy: 0.5282 - loss: 0.6925 - val_accuracy: 0.5933 - val_loss: 0.6791\n",
      "Epoch 8/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 178ms/step - accuracy: 0.5422 - loss: 0.6880 - val_accuracy: 0.6020 - val_loss: 0.6770\n",
      "Epoch 9/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 184ms/step - accuracy: 0.5565 - loss: 0.6839 - val_accuracy: 0.6143 - val_loss: 0.6747\n",
      "Epoch 10/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 182ms/step - accuracy: 0.5436 - loss: 0.6840 - val_accuracy: 0.6218 - val_loss: 0.6728\n",
      "Epoch 11/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 181ms/step - accuracy: 0.5502 - loss: 0.6847 - val_accuracy: 0.6341 - val_loss: 0.6708\n",
      "Epoch 12/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 182ms/step - accuracy: 0.5679 - loss: 0.6782 - val_accuracy: 0.6378 - val_loss: 0.6690\n",
      "Epoch 13/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 183ms/step - accuracy: 0.5761 - loss: 0.6758 - val_accuracy: 0.6366 - val_loss: 0.6673\n",
      "Epoch 14/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 180ms/step - accuracy: 0.5827 - loss: 0.6737 - val_accuracy: 0.6218 - val_loss: 0.6663\n",
      "Epoch 15/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 170ms/step - accuracy: 0.5732 - loss: 0.6736 - val_accuracy: 0.6391 - val_loss: 0.6640\n",
      "Epoch 16/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 178ms/step - accuracy: 0.5970 - loss: 0.6694 - val_accuracy: 0.6366 - val_loss: 0.6626\n",
      "Epoch 17/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 128ms/step - accuracy: 0.5886 - loss: 0.6690 - val_accuracy: 0.6539 - val_loss: 0.6610\n",
      "Epoch 18/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 198ms/step - accuracy: 0.6029 - loss: 0.6678 - val_accuracy: 0.6403 - val_loss: 0.6596\n",
      "Epoch 19/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 132ms/step - accuracy: 0.5872 - loss: 0.6684 - val_accuracy: 0.6465 - val_loss: 0.6585\n",
      "Epoch 20/100\n",
      "\u001b[1m237/237\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 158ms/step - accuracy: 0.6068 - loss: 0.6660 - val_accuracy: 0.6440 - val_loss: 0.6570\n",
      "Epoch 20: early stopping\n",
      "Restoring model weights from the end of the best epoch: 17.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 235ms/step\n",
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n",
      "Done → /Volumes/Sarbajit/Model Optimization/Transfer Learning Model/Output/mobilenetv3/Oral_Cancer\n",
      "\n",
      "================================================================================\n",
      "DATASET: Skin Leison (Skin_Leison)\n",
      "================================================================================\n",
      "   → 1763 images | 8 classes\n",
      "Found 1234 validated image filenames belonging to 8 classes.\n",
      "Found 264 validated image filenames belonging to 8 classes.\n",
      "Found 265 validated image filenames belonging to 8 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(40186) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   → Class weights: {0: 1.0422297297297298, 1: 0.9640625, 2: 1.0283333333333333, 3: 1.195736434108527, 4: 0.8764204545454546, 5: 0.842896174863388, 6: 0.9521604938271605, 7: 1.2242063492063493}\n",
      "\n",
      "--- Training RESNET50V2 on Skin_Leison ---\n",
      "Epoch 1/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 549ms/step - accuracy: 0.1896 - loss: 2.2746 - val_accuracy: 0.3939 - val_loss: 1.6827\n",
      "Epoch 2/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 271ms/step - accuracy: 0.4449 - loss: 1.5603 - val_accuracy: 0.6023 - val_loss: 1.2369\n",
      "Epoch 3/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 263ms/step - accuracy: 0.5972 - loss: 1.1902 - val_accuracy: 0.7045 - val_loss: 0.9742\n",
      "Epoch 4/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 262ms/step - accuracy: 0.6985 - loss: 0.9535 - val_accuracy: 0.7879 - val_loss: 0.8074\n",
      "Epoch 5/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 263ms/step - accuracy: 0.7553 - loss: 0.7994 - val_accuracy: 0.8295 - val_loss: 0.6955\n",
      "Epoch 6/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 265ms/step - accuracy: 0.7925 - loss: 0.6756 - val_accuracy: 0.8409 - val_loss: 0.6151\n",
      "Epoch 7/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 257ms/step - accuracy: 0.8201 - loss: 0.6063 - val_accuracy: 0.8523 - val_loss: 0.5566\n",
      "Epoch 8/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 256ms/step - accuracy: 0.8493 - loss: 0.5237 - val_accuracy: 0.8523 - val_loss: 0.5117\n",
      "Epoch 9/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 220ms/step - accuracy: 0.8768 - loss: 0.4630 - val_accuracy: 0.8712 - val_loss: 0.4747\n",
      "Epoch 10/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 223ms/step - accuracy: 0.8679 - loss: 0.4354 - val_accuracy: 0.8788 - val_loss: 0.4469\n",
      "Epoch 11/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 257ms/step - accuracy: 0.8955 - loss: 0.3909 - val_accuracy: 0.8826 - val_loss: 0.4214\n",
      "Epoch 12/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 254ms/step - accuracy: 0.8955 - loss: 0.3691 - val_accuracy: 0.8826 - val_loss: 0.4013\n",
      "Epoch 13/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 256ms/step - accuracy: 0.9060 - loss: 0.3504 - val_accuracy: 0.8864 - val_loss: 0.3821\n",
      "Epoch 14/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 233ms/step - accuracy: 0.9133 - loss: 0.3250 - val_accuracy: 0.8902 - val_loss: 0.3635\n",
      "Epoch 15/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 254ms/step - accuracy: 0.9149 - loss: 0.3043 - val_accuracy: 0.8939 - val_loss: 0.3458\n",
      "Epoch 16/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 258ms/step - accuracy: 0.9246 - loss: 0.2794 - val_accuracy: 0.8939 - val_loss: 0.3368\n",
      "Epoch 17/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 256ms/step - accuracy: 0.9295 - loss: 0.2769 - val_accuracy: 0.8902 - val_loss: 0.3262\n",
      "Epoch 18/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 265ms/step - accuracy: 0.9206 - loss: 0.2610 - val_accuracy: 0.8902 - val_loss: 0.3157\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 15.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 879ms/step\n",
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(40463) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done → /Volumes/Sarbajit/Model Optimization/Transfer Learning Model/Output/resnet50v2/Skin_Leison\n",
      "\n",
      "--- Training VGG19 on Skin_Leison ---\n",
      "Epoch 1/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 341ms/step - accuracy: 0.1451 - loss: 2.1324 - val_accuracy: 0.2348 - val_loss: 2.0253\n",
      "Epoch 2/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 278ms/step - accuracy: 0.1702 - loss: 2.0609 - val_accuracy: 0.2955 - val_loss: 1.9696\n",
      "Epoch 3/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 277ms/step - accuracy: 0.2050 - loss: 2.0131 - val_accuracy: 0.4091 - val_loss: 1.9201\n",
      "Epoch 4/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 276ms/step - accuracy: 0.2382 - loss: 1.9406 - val_accuracy: 0.5455 - val_loss: 1.8697\n",
      "Epoch 5/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 283ms/step - accuracy: 0.2804 - loss: 1.8902 - val_accuracy: 0.5568 - val_loss: 1.8248\n",
      "Epoch 6/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 275ms/step - accuracy: 0.3079 - loss: 1.8488 - val_accuracy: 0.5833 - val_loss: 1.7800\n",
      "Epoch 7/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 278ms/step - accuracy: 0.3412 - loss: 1.8176 - val_accuracy: 0.6439 - val_loss: 1.7370\n",
      "Epoch 8/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 277ms/step - accuracy: 0.3857 - loss: 1.7665 - val_accuracy: 0.6553 - val_loss: 1.6969\n",
      "Epoch 9/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 275ms/step - accuracy: 0.4392 - loss: 1.7129 - val_accuracy: 0.6818 - val_loss: 1.6580\n",
      "Epoch 10/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 277ms/step - accuracy: 0.4797 - loss: 1.6700 - val_accuracy: 0.7083 - val_loss: 1.6212\n",
      "Epoch 11/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 273ms/step - accuracy: 0.4976 - loss: 1.6308 - val_accuracy: 0.7235 - val_loss: 1.5847\n",
      "Epoch 12/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 274ms/step - accuracy: 0.5494 - loss: 1.5687 - val_accuracy: 0.7500 - val_loss: 1.5513\n",
      "Epoch 13/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 273ms/step - accuracy: 0.5511 - loss: 1.5649 - val_accuracy: 0.7538 - val_loss: 1.5187\n",
      "Epoch 14/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 278ms/step - accuracy: 0.5737 - loss: 1.5214 - val_accuracy: 0.7538 - val_loss: 1.4873\n",
      "Epoch 15/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 279ms/step - accuracy: 0.5721 - loss: 1.5144 - val_accuracy: 0.7765 - val_loss: 1.4572\n",
      "Epoch 16/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 288ms/step - accuracy: 0.6151 - loss: 1.4653 - val_accuracy: 0.7879 - val_loss: 1.4271\n",
      "Epoch 17/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 273ms/step - accuracy: 0.6491 - loss: 1.4299 - val_accuracy: 0.7879 - val_loss: 1.4006\n",
      "Epoch 18/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 274ms/step - accuracy: 0.6686 - loss: 1.4046 - val_accuracy: 0.7955 - val_loss: 1.3741\n",
      "Epoch 19/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 255ms/step - accuracy: 0.6572 - loss: 1.3852 - val_accuracy: 0.7841 - val_loss: 1.3499\n",
      "Epoch 20/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 273ms/step - accuracy: 0.7002 - loss: 1.3455 - val_accuracy: 0.7955 - val_loss: 1.3261\n",
      "Epoch 21/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 274ms/step - accuracy: 0.6831 - loss: 1.3227 - val_accuracy: 0.7879 - val_loss: 1.3010\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 324ms/step\n",
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(40700) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done → /Volumes/Sarbajit/Model Optimization/Transfer Learning Model/Output/vgg19/Skin_Leison\n",
      "\n",
      "--- Training MOBILENETV3 on Skin_Leison ---\n",
      "Epoch 1/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 362ms/step - accuracy: 0.1175 - loss: 2.2681 - val_accuracy: 0.1288 - val_loss: 2.1088\n",
      "Epoch 2/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 212ms/step - accuracy: 0.1272 - loss: 2.1717 - val_accuracy: 0.1477 - val_loss: 2.0400\n",
      "Epoch 3/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 187ms/step - accuracy: 0.1564 - loss: 2.0921 - val_accuracy: 0.1818 - val_loss: 1.9943\n",
      "Epoch 4/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 186ms/step - accuracy: 0.1856 - loss: 2.0512 - val_accuracy: 0.1364 - val_loss: 1.9623\n",
      "Epoch 5/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 188ms/step - accuracy: 0.1985 - loss: 2.0293 - val_accuracy: 0.2083 - val_loss: 1.9371\n",
      "Epoch 6/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 190ms/step - accuracy: 0.2083 - loss: 1.9933 - val_accuracy: 0.1970 - val_loss: 1.9188\n",
      "Epoch 7/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 184ms/step - accuracy: 0.2026 - loss: 1.9920 - val_accuracy: 0.2386 - val_loss: 1.9049\n",
      "Epoch 8/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 201ms/step - accuracy: 0.2180 - loss: 1.9726 - val_accuracy: 0.2727 - val_loss: 1.8922\n",
      "Epoch 9/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 187ms/step - accuracy: 0.2212 - loss: 1.9429 - val_accuracy: 0.2462 - val_loss: 1.8816\n",
      "Epoch 10/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 183ms/step - accuracy: 0.2342 - loss: 1.9326 - val_accuracy: 0.4432 - val_loss: 1.8707\n",
      "Epoch 11/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 183ms/step - accuracy: 0.2229 - loss: 1.9207 - val_accuracy: 0.2462 - val_loss: 1.8630\n",
      "Epoch 12/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 182ms/step - accuracy: 0.2334 - loss: 1.9073 - val_accuracy: 0.3333 - val_loss: 1.8523\n",
      "Epoch 13/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 186ms/step - accuracy: 0.2423 - loss: 1.8996 - val_accuracy: 0.5076 - val_loss: 1.8427\n",
      "Epoch 14/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 183ms/step - accuracy: 0.2561 - loss: 1.8844 - val_accuracy: 0.3598 - val_loss: 1.8355\n",
      "Epoch 15/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 183ms/step - accuracy: 0.2682 - loss: 1.8720 - val_accuracy: 0.3258 - val_loss: 1.8291\n",
      "Epoch 16/100\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 183ms/step - accuracy: 0.2407 - loss: 1.8832 - val_accuracy: 0.3371 - val_loss: 1.8219\n",
      "Epoch 16: early stopping\n",
      "Restoring model weights from the end of the best epoch: 13.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 397ms/step\n",
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(40865) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done → /Volumes/Sarbajit/Model Optimization/Transfer Learning Model/Output/mobilenetv3/Skin_Leison\n",
      "\n",
      "================================================================================\n",
      "DATASET: chest_xray (Chest_Xray)\n",
      "================================================================================\n",
      "   → 8546 images | 2 classes\n",
      "Found 5982 validated image filenames belonging to 2 classes.\n",
      "Found 1282 validated image filenames belonging to 2 classes.\n",
      "Found 1282 validated image filenames belonging to 2 classes.\n",
      "   → Class weights: {0: 1.0, 1: 1.0}\n",
      "\n",
      "--- Training RESNET50V2 on Chest_Xray ---\n",
      "Epoch 1/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 313ms/step - accuracy: 0.6237 - loss: 0.6836 - val_accuracy: 0.8721 - val_loss: 0.3735\n",
      "Epoch 2/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 275ms/step - accuracy: 0.8607 - loss: 0.3516 - val_accuracy: 0.9150 - val_loss: 0.2550\n",
      "Epoch 3/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 268ms/step - accuracy: 0.8990 - loss: 0.2672 - val_accuracy: 0.9275 - val_loss: 0.2103\n",
      "Epoch 4/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 263ms/step - accuracy: 0.9201 - loss: 0.2194 - val_accuracy: 0.9337 - val_loss: 0.1862\n",
      "Epoch 5/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 252ms/step - accuracy: 0.9239 - loss: 0.2035 - val_accuracy: 0.9384 - val_loss: 0.1704\n",
      "Epoch 6/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 250ms/step - accuracy: 0.9346 - loss: 0.1815 - val_accuracy: 0.9399 - val_loss: 0.1592\n",
      "Epoch 7/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 274ms/step - accuracy: 0.9423 - loss: 0.1655 - val_accuracy: 0.9438 - val_loss: 0.1512\n",
      "Epoch 8/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 269ms/step - accuracy: 0.9403 - loss: 0.1591 - val_accuracy: 0.9462 - val_loss: 0.1453\n",
      "Epoch 9/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 267ms/step - accuracy: 0.9483 - loss: 0.1514 - val_accuracy: 0.9485 - val_loss: 0.1396\n",
      "Epoch 10/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 252ms/step - accuracy: 0.9505 - loss: 0.1447 - val_accuracy: 0.9532 - val_loss: 0.1341\n",
      "Epoch 11/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 263ms/step - accuracy: 0.9472 - loss: 0.1460 - val_accuracy: 0.9548 - val_loss: 0.1306\n",
      "Epoch 12/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 261ms/step - accuracy: 0.9500 - loss: 0.1326 - val_accuracy: 0.9555 - val_loss: 0.1270\n",
      "Epoch 13/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 266ms/step - accuracy: 0.9545 - loss: 0.1331 - val_accuracy: 0.9571 - val_loss: 0.1241\n",
      "Epoch 14/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 264ms/step - accuracy: 0.9532 - loss: 0.1293 - val_accuracy: 0.9571 - val_loss: 0.1214\n",
      "Epoch 15/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 252ms/step - accuracy: 0.9554 - loss: 0.1253 - val_accuracy: 0.9587 - val_loss: 0.1191\n",
      "Epoch 16/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 259ms/step - accuracy: 0.9579 - loss: 0.1224 - val_accuracy: 0.9587 - val_loss: 0.1177\n",
      "Epoch 17/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 264ms/step - accuracy: 0.9554 - loss: 0.1226 - val_accuracy: 0.9618 - val_loss: 0.1160\n",
      "Epoch 18/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 263ms/step - accuracy: 0.9582 - loss: 0.1203 - val_accuracy: 0.9610 - val_loss: 0.1143\n",
      "Epoch 19/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 266ms/step - accuracy: 0.9572 - loss: 0.1205 - val_accuracy: 0.9626 - val_loss: 0.1128\n",
      "Epoch 20/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 252ms/step - accuracy: 0.9605 - loss: 0.1171 - val_accuracy: 0.9618 - val_loss: 0.1112\n",
      "Epoch 21/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 268ms/step - accuracy: 0.9622 - loss: 0.1143 - val_accuracy: 0.9633 - val_loss: 0.1100\n",
      "Epoch 22/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 263ms/step - accuracy: 0.9602 - loss: 0.1137 - val_accuracy: 0.9633 - val_loss: 0.1097\n",
      "Epoch 23/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 261ms/step - accuracy: 0.9604 - loss: 0.1124 - val_accuracy: 0.9626 - val_loss: 0.1080\n",
      "Epoch 24/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 259ms/step - accuracy: 0.9612 - loss: 0.1099 - val_accuracy: 0.9626 - val_loss: 0.1070\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 255ms/step\n",
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(42148) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done → /Volumes/Sarbajit/Model Optimization/Transfer Learning Model/Output/resnet50v2/Chest_Xray\n",
      "\n",
      "--- Training VGG19 on Chest_Xray ---\n",
      "Epoch 1/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 280ms/step - accuracy: 0.5092 - loss: 0.7109 - val_accuracy: 0.7340 - val_loss: 0.6663\n",
      "Epoch 2/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 276ms/step - accuracy: 0.6051 - loss: 0.6609 - val_accuracy: 0.8432 - val_loss: 0.6269\n",
      "Epoch 3/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 538ms/step - accuracy: 0.7085 - loss: 0.6181 - val_accuracy: 0.9009 - val_loss: 0.5915\n",
      "Epoch 4/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 590ms/step - accuracy: 0.7646 - loss: 0.5869 - val_accuracy: 0.9111 - val_loss: 0.5594\n",
      "Epoch 5/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 587ms/step - accuracy: 0.8283 - loss: 0.5516 - val_accuracy: 0.9212 - val_loss: 0.5305\n",
      "Epoch 6/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 598ms/step - accuracy: 0.8509 - loss: 0.5235 - val_accuracy: 0.9228 - val_loss: 0.5045\n",
      "Epoch 7/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m214s\u001b[0m 573ms/step - accuracy: 0.8681 - loss: 0.4971 - val_accuracy: 0.9189 - val_loss: 0.4818\n",
      "Epoch 8/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 588ms/step - accuracy: 0.8766 - loss: 0.4778 - val_accuracy: 0.9220 - val_loss: 0.4596\n",
      "Epoch 9/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 583ms/step - accuracy: 0.8860 - loss: 0.4563 - val_accuracy: 0.9204 - val_loss: 0.4400\n",
      "Epoch 9: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 432ms/step\n",
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(42978) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done → /Volumes/Sarbajit/Model Optimization/Transfer Learning Model/Output/vgg19/Chest_Xray\n",
      "\n",
      "--- Training MOBILENETV3 on Chest_Xray ---\n",
      "Epoch 1/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 533ms/step - accuracy: 0.5515 - loss: 0.6851 - val_accuracy: 0.7441 - val_loss: 0.6598\n",
      "Epoch 2/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 546ms/step - accuracy: 0.6133 - loss: 0.6582 - val_accuracy: 0.7262 - val_loss: 0.6405\n",
      "Epoch 3/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 547ms/step - accuracy: 0.6713 - loss: 0.6342 - val_accuracy: 0.7184 - val_loss: 0.6242\n",
      "Epoch 4/100\n",
      "\u001b[1m374/374\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 489ms/step - accuracy: 0.6937 - loss: 0.6190 - val_accuracy: 0.7293 - val_loss: 0.6110\n",
      "Epoch 4: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 496ms/step\n",
      "You must install graphviz (see instructions at https://graphviz.gitlab.io/download/) for `plot_model` to work.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(43505) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done → /Volumes/Sarbajit/Model Optimization/Transfer Learning Model/Output/mobilenetv3/Chest_Xray\n",
      "\n",
      "ALL TRAINING COMPLETED! Output folder:\n",
      "/Volumes/Sarbajit/Model Optimization/Transfer Learning Model/Output\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 6: MAIN SEQUENTIAL TRAINING LOOP (fixed version)\n",
    "# ============================================================\n",
    "\n",
    "for short_name, pretty_name in modalities.items():\n",
    "    dataset_path = BASE_DATA_PATH / pretty_name\n",
    "    if not dataset_path.exists():\n",
    "        print(f\"[SKIP] {dataset_path} not found\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"DATASET: {pretty_name} ({short_name})\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    df = load_dataframe(dataset_path)\n",
    "    n_classes = df['Label'].nunique()\n",
    "    print(f\"   → {len(df)} images | {n_classes} classes\")\n",
    "\n",
    "    # Generators (224x224 only)\n",
    "    train_gen, val_gen, test_gen = create_generators(df)\n",
    "    class_names = get_class_names(train_gen)\n",
    "    class_weights = compute_class_weights(train_gen)\n",
    "    print(f\"   → Class weights: {class_weights}\")\n",
    "\n",
    "    for model_key, builder in MODEL_BUILDERS.items():\n",
    "        print(f\"\\n--- Training {model_key.upper()} on {short_name} ---\")\n",
    "        out_dir = OUTPUT_ROOT / model_key / short_name\n",
    "        out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Build model\n",
    "        model = builder(n_classes)\n",
    "\n",
    "        # Callbacks\n",
    "        ckpt_path = out_dir / f\"{model_key}_{short_name}_best.h5\"\n",
    "        callbacks_list = [\n",
    "            callbacks.EarlyStopping(monitor='val_accuracy', patience=PATIENCE,\n",
    "                                    restore_best_weights=True, verbose=1)\n",
    "        ]\n",
    "\n",
    "        # Train\n",
    "        hist = model.fit(\n",
    "            train_gen,\n",
    "            validation_data=val_gen,\n",
    "            epochs=EPOCHS,\n",
    "            callbacks=callbacks_list,\n",
    "            class_weight=class_weights,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # Save final model\n",
    "        final_path = out_dir / f\"{model_key}_{short_name}_final.h5\"\n",
    "        model.save(final_path)\n",
    "\n",
    "        # Visualizations\n",
    "        save_history_plot(hist, out_dir)\n",
    "\n",
    "        # Test evaluation\n",
    "        test_gen.reset()\n",
    "        true_cls = test_gen.classes\n",
    "\n",
    "        # Binary vs multiclass logic (robust)\n",
    "        pred_proba = model.predict(test_gen, verbose=1)\n",
    "        if n_classes == 2:\n",
    "            if pred_proba.ndim > 1:\n",
    "                pred_proba = pred_proba.ravel()\n",
    "            pred_cls = (pred_proba > 0.5).astype(int)\n",
    "            true_onehot = to_categorical(true_cls, 2)\n",
    "        else:\n",
    "            pred_cls = np.argmax(pred_proba, axis=1)\n",
    "            true_onehot = to_categorical(true_cls, n_classes)\n",
    "\n",
    "        # Metrics & plots\n",
    "        save_confusion_matrix(true_cls, pred_cls, class_names, out_dir)\n",
    "        save_classification_report(true_cls, pred_cls, class_names, out_dir)\n",
    "        save_roc_auc(true_onehot, pred_proba, class_names, out_dir)\n",
    "\n",
    "        # Model architecture visualization\n",
    "        plot_model(model, to_file=out_dir / 'architecture.png', show_shapes=True, dpi=180)\n",
    "\n",
    "        # Summary JSON\n",
    "        summary = {\n",
    "            'dataset': pretty_name,\n",
    "            'model': model_key,\n",
    "            'num_classes': n_classes,\n",
    "            'test_accuracy': float(np.mean(pred_cls == true_cls)),\n",
    "            'best_model': str(ckpt_path),\n",
    "            'final_model': str(final_path),\n",
    "            'class_weights': class_weights\n",
    "        }\n",
    "        json.dump(summary, open(out_dir / 'summary.json', 'w'), indent=2)\n",
    "        print(f\"Done → {out_dir}\")\n",
    "\n",
    "print(\"\\nALL TRAINING COMPLETED! Output folder:\")\n",
    "print(OUTPUT_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebf6fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
